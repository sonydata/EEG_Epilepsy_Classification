{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "103JO6TM2hFe4oBU8TGyfw951uRcW4tUr",
      "authorship_tag": "ABX9TyOHNfjt5ssiyi2XRRuhC3j1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sonydata/EEG_Epilepsy_Classification/blob/main/EEG_Features_extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install libraries"
      ],
      "metadata": {
        "id": "H3D4zwQ70dS7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBeBPVJwz9us",
        "outputId": "296813f5-a974-4418-a203-573a682a2113"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mne in /usr/local/lib/python3.11/dist-packages (1.9.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from mne) (3.1.6)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.11/dist-packages (from mne) (0.4)\n",
            "Requirement already satisfied: matplotlib>=3.6 in /usr/local/lib/python3.11/dist-packages (from mne) (3.10.0)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from mne) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from mne) (24.2)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.11/dist-packages (from mne) (1.8.2)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.11/dist-packages (from mne) (1.14.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from mne) (4.67.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (2.8.2)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.5->mne) (4.3.7)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.5->mne) (2.32.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->mne) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.6->mne) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2025.1.31)\n",
            "Collecting antropy\n",
            "  Downloading antropy-0.1.9-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from antropy) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from antropy) (1.14.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from antropy) (1.6.1)\n",
            "Requirement already satisfied: numba>=0.57 in /usr/local/lib/python3.11/dist-packages (from antropy) (0.60.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.57->antropy) (0.43.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->antropy) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->antropy) (3.6.0)\n",
            "Downloading antropy-0.1.9-py3-none-any.whl (18 kB)\n",
            "Installing collected packages: antropy\n",
            "Successfully installed antropy-0.1.9\n"
          ]
        }
      ],
      "source": [
        "! pip install mne\n",
        "! pip install antropy\n",
        "\n",
        "import mne\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.signal import welch\n",
        "from scipy.stats import skew, kurtosis\n",
        "from antropy import sample_entropy, perm_entropy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read EDF files"
      ],
      "metadata": {
        "id": "mP3N4LhP0fJx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace with the path to your EDF file\n",
        "raw = mne.io.read_raw_edf('/content/sample_data/aaaaaanr_s001_t001.edf', preload=True)\n",
        "\n",
        "# Print high-level info (channels, sampling freq, etc.)\n",
        "print(raw.info)\n",
        "\n",
        "# Access the data and sampling rate\n",
        "data, times = raw.get_data(return_times=True)\n",
        "sfreq = raw.info['sfreq']  # Sampling frequency\n",
        "ch_names = raw.info['ch_names']\n",
        "print(\"Sampling Frequency:\", sfreq)\n",
        "print(\"Channel Names:\", ch_names)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kgrv0sgj0i2L",
        "outputId": "7c9211f5-c0bb-4d6f-938f-d63768eacd6b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting EDF parameters from /content/sample_data/aaaaaanr_s001_t001.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 303499  =      0.000 ...  1213.996 secs...\n",
            "<Info | 8 non-empty values\n",
            " bads: []\n",
            " ch_names: EEG FP1-LE, EEG FP2-LE, EEG F3-LE, EEG F4-LE, EEG C3-LE, EEG ...\n",
            " chs: 33 EEG\n",
            " custom_ref_applied: False\n",
            " highpass: 0.0 Hz\n",
            " lowpass: 125.0 Hz\n",
            " meas_date: 2003-01-01 00:00:00 UTC\n",
            " nchan: 33\n",
            " projs: []\n",
            " sfreq: 250.0 Hz\n",
            " subject_info: <subject_info | his_id: aaaaaanr, sex: 1, last_name: aaaaaanr>\n",
            ">\n",
            "Sampling Frequency: 250.0\n",
            "Channel Names: ['EEG FP1-LE', 'EEG FP2-LE', 'EEG F3-LE', 'EEG F4-LE', 'EEG C3-LE', 'EEG C4-LE', 'EEG A1-LE', 'EEG A2-LE', 'EEG P3-LE', 'EEG P4-LE', 'EEG O1-LE', 'EEG O2-LE', 'EEG F7-LE', 'EEG F8-LE', 'EEG T3-LE', 'EEG T4-LE', 'EEG T5-LE', 'EEG T6-LE', 'EEG FZ-LE', 'EEG CZ-LE', 'EEG PZ-LE', 'EEG OZ-LE', 'EEG PG1-LE', 'EEG PG2-LE', 'EEG EKG-LE', 'EEG SP2-LE', 'EEG SP1-LE', 'EEG 28-LE', 'EEG 29-LE', 'EEG 30-LE', 'EEG T1-LE', 'EEG T2-LE', 'PHOTIC PH']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check low-level EDF header\n",
        "edf_header = raw._raw_extras[0]\n",
        "print(\"EDF Header:\", edf_header)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ynrh8j7ZMDLz",
        "outputId": "fc2d4544-c323-4eff-b460-2901fdcd8969"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EDF Header: {'events': [], 'units': array([1.e-06, 1.e-06, 1.e-06, 1.e-06, 1.e-06, 1.e-06, 1.e-06, 1.e-06,\n",
            "       1.e-06, 1.e-06, 1.e-06, 1.e-06, 1.e-06, 1.e-06, 1.e-06, 1.e-06,\n",
            "       1.e-06, 1.e-06, 1.e-06, 1.e-06, 1.e-06, 1.e-06, 1.e-06, 1.e-06,\n",
            "       1.e-06, 1.e-06, 1.e-06, 1.e-06, 1.e-06, 1.e-06, 1.e-06, 1.e-06,\n",
            "       1.e+00]), 'ch_names': ['EEG FP1-LE', 'EEG FP2-LE', 'EEG F3-LE', 'EEG F4-LE', 'EEG C3-LE', 'EEG C4-LE', 'EEG A1-LE', 'EEG A2-LE', 'EEG P3-LE', 'EEG P4-LE', 'EEG O1-LE', 'EEG O2-LE', 'EEG F7-LE', 'EEG F8-LE', 'EEG T3-LE', 'EEG T4-LE', 'EEG T5-LE', 'EEG T6-LE', 'EEG FZ-LE', 'EEG CZ-LE', 'EEG PZ-LE', 'EEG OZ-LE', 'EEG PG1-LE', 'EEG PG2-LE', 'EEG EKG-LE', 'EEG SP2-LE', 'EEG SP1-LE', 'EEG 28-LE', 'EEG 29-LE', 'EEG 30-LE', 'EEG T1-LE', 'EEG T2-LE', 'PHOTIC PH'], 'ch_types': ['EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG', 'EEG'], 'data_offset': 8704, 'digital_max': array([32767., 32767., 32767., 32767., 32767., 32767., 32767., 32767.,\n",
            "       32767., 32767., 32767., 32767., 32767., 32767., 32767., 32767.,\n",
            "       32767., 32767., 32767., 32767., 32767., 32767., 32767., 32767.,\n",
            "       32767., 32767., 32767., 32767., 32767., 32767., 32767., 32767.,\n",
            "       32767.]), 'highpass': array(['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
            "       '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ''],\n",
            "      dtype='<U1'), 'sel': array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
            "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32]), 'lowpass': array(['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
            "       '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', ''],\n",
            "      dtype='<U1'), 'n_records': 1214, 'n_samps': array([250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250,\n",
            "       250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250, 250,\n",
            "       250, 250, 250, 250, 250, 250, 250]), 'nchan': 33, 'physical_max': array([ 4999.85,  4999.85,  4999.85,  4999.85,  4999.85,  4999.85,\n",
            "        4999.85,  4999.85,  4999.85,  4999.85,  4999.85,  4999.85,\n",
            "        4999.85,  4999.85,  4999.85,  4999.85,  4999.85,  4999.85,\n",
            "        4999.85,  4999.85,  4999.85,  4999.85,  4999.85,  4999.85,\n",
            "        4999.85,  4999.85,  4999.85,  4999.85,  4999.85,  4999.85,\n",
            "        4999.85,  4999.85, 32767.  ]), 'record_length': array([1., 1.]), 'subtype': 'edf', 'tal_idx': array([], dtype=int64), 'dtype_byte': 2, 'dtype_np': '<i2', 'stim_channel_idxs': [], 'max_samp': np.int64(250), 'nsamples': 303500, 'cal': array([0.15258797, 0.15258797, 0.15258797, 0.15258797, 0.15258797,\n",
            "       0.15258797, 0.15258797, 0.15258797, 0.15258797, 0.15258797,\n",
            "       0.15258797, 0.15258797, 0.15258797, 0.15258797, 0.15258797,\n",
            "       0.15258797, 0.15258797, 0.15258797, 0.15258797, 0.15258797,\n",
            "       0.15258797, 0.15258797, 0.15258797, 0.15258797, 0.15258797,\n",
            "       0.15258797, 0.15258797, 0.15258797, 0.15258797, 0.15258797,\n",
            "       0.15258797, 0.15258797, 1.        ]), 'offsets': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), 'orig_nchan': 33}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Extract frequency-domain features"
      ],
      "metadata": {
        "id": "StsNt56N92Q4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Power Spectral Density (PSD) and Band Power\n",
        "A common approach uses the Welch method for estimating PSD. EEG signals are split into standard frequency bands. For epilepsy detection, these bands can help identify abnormal activity or changes in spectral power.\n",
        "\n",
        "* Delta: 0.5–4 Hz\n",
        "\n",
        "* Theta: 4–8 Hz\n",
        "\n",
        "* Alpha: 8–12 Hz\n",
        "\n",
        "* Beta: 12–30 Hz\n",
        "\n",
        "* Gamma: 30–45 (or 50) Hz\n",
        "\n",
        "**Band Power**\n",
        "\n",
        "We can compute relative band power by dividing each band’s power by the total power.\n",
        "\n",
        "Each band’s power (relative=True) is normalized by the total power across all frequencies, which gives more robust measures that are less sensitive to overall amplitude scaling."
      ],
      "metadata": {
        "id": "DNU6eW4uA7xL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def bandpower(data, sf, band, window_sec=4, relative=False):\n",
        "    \"\"\"\n",
        "    Compute the average power of the signal x in a specific frequency band.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    data : 1d-array\n",
        "        Input signal in the time-domain.\n",
        "    sf : float\n",
        "        Sampling frequency of the data.\n",
        "    band : tuple\n",
        "        Lower and upper frequencies of the band of interest.\n",
        "    window_sec : float\n",
        "        Length of each Welch segment in seconds.\n",
        "    relative : bool\n",
        "        If True, return the relative power (proportion of total power in the band).\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    bp : float\n",
        "        Band power.\n",
        "    \"\"\"\n",
        "    band = np.asarray(band)\n",
        "    low, high = band\n",
        "\n",
        "    # Compute Welch’s periodogram\n",
        "    nperseg = int(window_sec * sf)\n",
        "    freqs, psd = welch(data, sf, nperseg=nperseg)\n",
        "\n",
        "    # Frequency resolution\n",
        "    freq_res = freqs[1] - freqs[0]\n",
        "\n",
        "    # Find the indices of freqs in the band\n",
        "    idx_band = np.logical_and(freqs >= low, freqs <= high)\n",
        "\n",
        "    # Integral approximation of the power spectral density over that band\n",
        "    bp = np.trapz(psd[idx_band], dx=freq_res)\n",
        "\n",
        "    if relative:\n",
        "        bp /= np.trapz(psd, dx=freq_res)\n",
        "    return bp\n"
      ],
      "metadata": {
        "id": "MyQyVDMS1m2o"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Time-Domain Features\n"
      ],
      "metadata": {
        "id": "Py_8LRbiAsSo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Common time-domain features:\n",
        "\n",
        "* Mean\n",
        "* Variance\n",
        "* Skewness\n",
        "* Kurtosis\n",
        "* Zero-Crossing Rate\n",
        "* Teager-Kaiser Energy Operator (TKEO)"
      ],
      "metadata": {
        "id": "8Q99aozeA3Wh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_time_domain_features(signal):\n",
        "    mean_val = np.mean(signal)\n",
        "    var_val = np.var(signal)\n",
        "    skew_val = skew(signal)\n",
        "    kurt_val = kurtosis(signal, fisher=False)  # 'fisher=False' to match normal=3\n",
        "    # Zero-crossing rate\n",
        "    zero_crossings = np.where(np.diff(np.sign(signal)))[0]\n",
        "    zcr = len(zero_crossings) / len(signal)\n",
        "\n",
        "    # Teager-Kaiser Energy Operator\n",
        "    # TKEO(s) = x[n]^2 - x[n-1]*x[n+1]\n",
        "    tkeo = np.mean(signal[1:-1]**2 - signal[:-2] * signal[2:])\n",
        "\n",
        "    return {\n",
        "        'mean': mean_val,\n",
        "        'variance': var_val,\n",
        "        'skewness': skew_val,\n",
        "        'kurtosis': kurt_val,\n",
        "        'zcr': zcr,\n",
        "        'tkeo': tkeo\n",
        "    }"
      ],
      "metadata": {
        "id": "VclG20nxAxdw"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Entropy and Complexity Measures\n",
        "Various entropy metrics are popular in seizure detection because they capture signal complexity. Two widely used measures:\n",
        "\n",
        "* Sample Entropy (SampEn): Measures of complexity based on the regularity of a time series\n",
        "\n",
        "* Permutation Entropy (PermEn): Looks at the order patterns of the signal values.\n"
      ],
      "metadata": {
        "id": "jdk2W66zODXo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "samp_en = sample_entropy(signal, order=2, r=0.2*np.std(signal))\n",
        "\n",
        "p_en = perm_entropy(signal, order=3, normalize=True)"
      ],
      "metadata": {
        "id": "hZhjEf5xUghi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Constructing a feature vector per window"
      ],
      "metadata": {
        "id": "FWcRmdnHOdrv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features_for_channel(signal, sf):\n",
        "    # Time-domain features\n",
        "    td_feats = compute_time_domain_features(signal)\n",
        "\n",
        "    # Frequency-domain features\n",
        "    freq_feats = {}\n",
        "    for band_name, freq_range in bands.items():\n",
        "        bp = bandpower(signal, sf, freq_range, window_sec=4, relative=True)\n",
        "        freq_feats[f'{band_name}_power'] = bp\n",
        "\n",
        "    # Entropy features\n",
        "    samp_en = sample_entropy(signal, order=2, r=0.2*np.std(signal))\n",
        "    p_en = perm_entropy(signal, order=3, normalize=True)\n",
        "    ent_feats = {\n",
        "        'sample_entropy': samp_en,\n",
        "        'perm_entropy': p_en\n",
        "    }\n",
        "\n",
        "    # Combine all dictionaries\n",
        "    combined = {**td_feats, **freq_feats, **ent_feats}\n",
        "    return combined\n",
        "\n",
        "# Example: looping over channels and windows\n",
        "all_features = []\n",
        "window_size = int(4 * sfreq)  # 4-second windows, for example\n",
        "overlap = 0.5  # 50% overlap\n",
        "\n",
        "step = int(window_size * (1 - overlap))\n",
        "n_samples = data.shape[1]\n",
        "\n",
        "for ch_idx in range(data.shape[0]):\n",
        "    ch_signal = data[ch_idx, :]\n",
        "    start = 0\n",
        "    while start + window_size < n_samples:\n",
        "        windowed_signal = ch_signal[start : start + window_size]\n",
        "        feats = extract_features_for_channel(windowed_signal, sfreq)\n",
        "        feats['channel'] = ch_names[ch_idx]\n",
        "        feats['start_sample'] = start\n",
        "        feats['end_sample'] = start + window_size\n",
        "        all_features.append(feats)\n",
        "        start += step\n",
        "\n",
        "df_features = pd.DataFrame(all_features)\n",
        "print(df_features.head())\n"
      ],
      "metadata": {
        "id": "9wL1CjxKOdYU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}