{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "103JO6TM2hFe4oBU8TGyfw951uRcW4tUr",
      "authorship_tag": "ABX9TyO6Y3s4PJiuers6Hwx2I6ie",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sonydata/EEG_Epilepsy_Classification/blob/main/EEG_Features_extraction_for_supervised_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install libraries"
      ],
      "metadata": {
        "id": "H3D4zwQ70dS7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBeBPVJwz9us",
        "outputId": "296813f5-a974-4418-a203-573a682a2113"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mne in /usr/local/lib/python3.11/dist-packages (1.9.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from mne) (3.1.6)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.11/dist-packages (from mne) (0.4)\n",
            "Requirement already satisfied: matplotlib>=3.6 in /usr/local/lib/python3.11/dist-packages (from mne) (3.10.0)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from mne) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from mne) (24.2)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.11/dist-packages (from mne) (1.8.2)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.11/dist-packages (from mne) (1.14.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from mne) (4.67.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (2.8.2)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.5->mne) (4.3.7)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.5->mne) (2.32.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->mne) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.6->mne) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2025.1.31)\n",
            "Collecting antropy\n",
            "  Downloading antropy-0.1.9-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from antropy) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from antropy) (1.14.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from antropy) (1.6.1)\n",
            "Requirement already satisfied: numba>=0.57 in /usr/local/lib/python3.11/dist-packages (from antropy) (0.60.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.57->antropy) (0.43.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->antropy) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->antropy) (3.6.0)\n",
            "Downloading antropy-0.1.9-py3-none-any.whl (18 kB)\n",
            "Installing collected packages: antropy\n",
            "Successfully installed antropy-0.1.9\n"
          ]
        }
      ],
      "source": [
        "! pip install mne\n",
        "! pip install antropy\n",
        "\n",
        "import mne\n",
        "import pywt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.signal import welch\n",
        "from scipy.stats import skew, kurtosis\n",
        "from antropy import sample_entropy, perm_entropy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read EDF files"
      ],
      "metadata": {
        "id": "mP3N4LhP0fJx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace with the path to your EDF file\n",
        "raw = mne.io.read_raw_edf('/content/sample_data/aaaaaanr_s001_t001.edf', preload=True)\n",
        "\n",
        "# Print high-level info (channels, sampling freq, etc.)\n",
        "print(raw.info)\n",
        "\n",
        "# Access the data and sampling rate\n",
        "data, times = raw.get_data(return_times=True)\n",
        "sfreq = raw.info['sfreq']  # Sampling frequency\n",
        "ch_names = raw.info['ch_names']\n",
        "print(\"Sampling Frequency:\", sfreq)\n",
        "print(\"Channel Names:\", ch_names)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kgrv0sgj0i2L",
        "outputId": "7c9211f5-c0bb-4d6f-938f-d63768eacd6b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting EDF parameters from /content/sample_data/aaaaaanr_s001_t001.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 303499  =      0.000 ...  1213.996 secs...\n",
            "<Info | 8 non-empty values\n",
            " bads: []\n",
            " ch_names: EEG FP1-LE, EEG FP2-LE, EEG F3-LE, EEG F4-LE, EEG C3-LE, EEG ...\n",
            " chs: 33 EEG\n",
            " custom_ref_applied: False\n",
            " highpass: 0.0 Hz\n",
            " lowpass: 125.0 Hz\n",
            " meas_date: 2003-01-01 00:00:00 UTC\n",
            " nchan: 33\n",
            " projs: []\n",
            " sfreq: 250.0 Hz\n",
            " subject_info: <subject_info | his_id: aaaaaanr, sex: 1, last_name: aaaaaanr>\n",
            ">\n",
            "Sampling Frequency: 250.0\n",
            "Channel Names: ['EEG FP1-LE', 'EEG FP2-LE', 'EEG F3-LE', 'EEG F4-LE', 'EEG C3-LE', 'EEG C4-LE', 'EEG A1-LE', 'EEG A2-LE', 'EEG P3-LE', 'EEG P4-LE', 'EEG O1-LE', 'EEG O2-LE', 'EEG F7-LE', 'EEG F8-LE', 'EEG T3-LE', 'EEG T4-LE', 'EEG T5-LE', 'EEG T6-LE', 'EEG FZ-LE', 'EEG CZ-LE', 'EEG PZ-LE', 'EEG OZ-LE', 'EEG PG1-LE', 'EEG PG2-LE', 'EEG EKG-LE', 'EEG SP2-LE', 'EEG SP1-LE', 'EEG 28-LE', 'EEG 29-LE', 'EEG 30-LE', 'EEG T1-LE', 'EEG T2-LE', 'PHOTIC PH']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Extract frequency-domain features"
      ],
      "metadata": {
        "id": "StsNt56N92Q4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Power Spectral Density (PSD) and Band Power\n",
        "A common approach uses the Welch method for estimating PSD. EEG signals are split into standard frequency bands. For epilepsy detection, these bands can help identify abnormal activity or changes in spectral power.\n",
        "\n",
        "* Delta: 0.5–4 Hz\n",
        "\n",
        "* Theta: 4–8 Hz\n",
        "\n",
        "* Alpha: 8–12 Hz\n",
        "\n",
        "* Beta: 12–30 Hz\n",
        "\n",
        "* Gamma: 30–45 (or 50) Hz\n",
        "\n",
        "**Band Power**\n",
        "\n",
        "We can compute relative band power by dividing each band’s power by the total power.\n",
        "\n",
        "Each band’s power (relative=True) is normalized by the total power across all frequencies, which gives more robust measures that are less sensitive to overall amplitude scaling."
      ],
      "metadata": {
        "id": "DNU6eW4uA7xL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def bandpower(data, sf, band, window_sec=4, relative=False):\n",
        "    \"\"\"\n",
        "    Compute the average power of the signal x in a specific frequency band.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    data : 1d-array\n",
        "        Input signal in the time-domain.\n",
        "    sf : float\n",
        "        Sampling frequency of the data.\n",
        "    band : tuple\n",
        "        Lower and upper frequencies of the band of interest.\n",
        "    window_sec : float\n",
        "        Length of each Welch segment in seconds.\n",
        "    relative : bool\n",
        "        If True, return the relative power (proportion of total power in the band).\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    bp : float\n",
        "        Band power.\n",
        "    \"\"\"\n",
        "    band = np.asarray(band)\n",
        "    low, high = band\n",
        "\n",
        "    # Compute Welch’s periodogram\n",
        "    nperseg = int(window_sec * sf)\n",
        "    freqs, psd = welch(data, sf, nperseg=nperseg)\n",
        "\n",
        "    # Frequency resolution\n",
        "    freq_res = freqs[1] - freqs[0]\n",
        "\n",
        "    # Find the indices of freqs in the band\n",
        "    idx_band = np.logical_and(freqs >= low, freqs <= high)\n",
        "\n",
        "    # Integral approximation of the power spectral density over that band\n",
        "    bp = np.trapz(psd[idx_band], dx=freq_res)\n",
        "\n",
        "    if relative:\n",
        "        bp /= np.trapz(psd, dx=freq_res)\n",
        "    return bp\n"
      ],
      "metadata": {
        "id": "MyQyVDMS1m2o"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Time-Domain Features\n"
      ],
      "metadata": {
        "id": "Py_8LRbiAsSo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Common time-domain features:\n",
        "\n",
        "* Mean\n",
        "* Variance\n",
        "* Skewness\n",
        "* Kurtosis\n",
        "* Zero-Crossing Rate\n",
        "* Teager-Kaiser Energy Operator (TKEO)"
      ],
      "metadata": {
        "id": "8Q99aozeA3Wh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_time_domain_features(signal):\n",
        "    mean_val = np.mean(signal)\n",
        "    var_val = np.var(signal)\n",
        "    skew_val = skew(signal)\n",
        "    kurt_val = kurtosis(signal, fisher=False)  # 'fisher=False' to match normal=3\n",
        "    # Zero-crossing rate\n",
        "    zero_crossings = np.where(np.diff(np.sign(signal)))[0]\n",
        "    zcr = len(zero_crossings) / len(signal)\n",
        "\n",
        "    # Teager-Kaiser Energy Operator\n",
        "    # TKEO(s) = x[n]^2 - x[n-1]*x[n+1]\n",
        "    tkeo = np.mean(signal[1:-1]**2 - signal[:-2] * signal[2:])\n",
        "\n",
        "    return {\n",
        "        'mean': mean_val,\n",
        "        'variance': var_val,\n",
        "        'skewness': skew_val,\n",
        "        'kurtosis': kurt_val,\n",
        "        'zcr': zcr,\n",
        "        'tkeo': tkeo\n",
        "    }"
      ],
      "metadata": {
        "id": "VclG20nxAxdw"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Entropy and Complexity Measures\n",
        "Various entropy metrics are popular in seizure detection because they capture signal complexity. Two widely used measures:\n",
        "\n",
        "* Sample Entropy (SampEn): Measures of complexity based on the regularity of a time series\n",
        "\n",
        "* Permutation Entropy (PermEn): Looks at the order patterns of the signal values.\n"
      ],
      "metadata": {
        "id": "jdk2W66zODXo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "samp_en = sample_entropy(signal, order=2, r=0.2*np.std(signal))\n",
        "\n",
        "p_en = perm_entropy(signal, order=3, normalize=True)"
      ],
      "metadata": {
        "id": "hZhjEf5xUghi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Wavelet Transform (Discrete Wavelet Transform – DWT)\n",
        "* Captures transient, non-stationary seizure events well.\n",
        "\n",
        "* Commonly used in many epilepsy-detection studies; wavelet coefficients (and wavelet-based entropy) often provide strong discriminative power.\n",
        "\n",
        "**Implementation Details**\n",
        "\n",
        "* Perform multi-level DWT (e.g., 4–6 levels), then extract features like energy, variance, or entropy from each level.\n",
        "\n",
        "* Keep feature size controlled to avoid overfitting (e.g., by focusing on relevant sub-bands: delta, theta, alpha, beta, gamma)."
      ],
      "metadata": {
        "id": "JP96evtGfC3f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_dwt_features(signal, wavelet='db4', level=4):\n",
        "    \"\"\"\n",
        "    Perform multi-level DWT on the input EEG segment and extract:\n",
        "      - Energy\n",
        "      - Variance\n",
        "      - Shannon Entropy\n",
        "    from each sub-band.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    signal : 1D array-like\n",
        "        Single-channel EEG segment (e.g., 2-second window).\n",
        "    wavelet : str\n",
        "        Type of mother wavelet to use (e.g., 'db4', 'sym5', 'coif5', etc.).\n",
        "    level : int\n",
        "        Number of decomposition levels.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    features : dict\n",
        "        Dictionary containing sub-band coefficients and their extracted features.\n",
        "        Also returns a combined feature vector for easy downstream use.\n",
        "    \"\"\"\n",
        "\n",
        "    # 1. Discrete Wavelet Decomposition\n",
        "    # coeffs[0] = approximation coefficients at level,\n",
        "    # coeffs[1:] = detail coefficients for each level\n",
        "    coeffs = pywt.wavedec(signal, wavelet=wavelet, level=level)\n",
        "\n",
        "    # Dictionary to store features for each sub-band\n",
        "    subband_features = {}\n",
        "\n",
        "    # We'll also create a feature vector list that we can later convert into a NumPy array\n",
        "    feature_vector = []\n",
        "\n",
        "    # 2. Loop through each sub-band (approx + details)\n",
        "    #   For a level-4 DWT, we’ll have 5 coefficient arrays: A4, D4, D3, D2, D1\n",
        "    #   You can rename them or store them differently if you prefer.\n",
        "    for i, c in enumerate(coeffs):\n",
        "        # Approximation is index 0, details are index 1..level\n",
        "        if i == 0:\n",
        "            band_name = f\"A{level}\"  # Approximation at highest level\n",
        "        else:\n",
        "            band_name = f\"D{level - i + 1}\"  # Detail coefficients\n",
        "\n",
        "        # Convert to NumPy array to ensure consistency\n",
        "        c = np.asarray(c)\n",
        "\n",
        "        # ---- Example features: Energy, Variance, Shannon Entropy ----\n",
        "        energy = np.sum(c**2)\n",
        "        variance = np.var(c)\n",
        "\n",
        "        # Shannon Entropy\n",
        "        #  - To ensure non-negativity, add a small epsilon before log\n",
        "        #  - Normalize so the sum of p_i = 1\n",
        "        p = np.abs(c)**2\n",
        "        p /= np.sum(p) + 1e-12  # normalization + epsilon\n",
        "        shannon_entropy = -np.sum(p * np.log2(p + 1e-12))\n",
        "\n",
        "        # Store them in a dictionary\n",
        "        subband_features[band_name] = {\n",
        "            \"coeffs\": c,\n",
        "            \"energy\": energy,\n",
        "            \"variance\": variance,\n",
        "            \"entropy\": shannon_entropy\n",
        "        }\n",
        "\n",
        "        # Append to our feature vector\n",
        "        feature_vector.extend([energy, variance, shannon_entropy])\n",
        "\n",
        "    # Convert feature_vector list to a NumPy array for easy downstream use\n",
        "    feature_vector = np.array(feature_vector, dtype=float)\n",
        "\n",
        "    # Add the combined feature vector to the dictionary for convenience\n",
        "    subband_features[\"feature_vector\"] = feature_vector\n",
        "\n",
        "    return subband_features\n",
        "\n",
        "# ---------------------------------------------\n",
        "# Example usage:\n",
        "# (You might normally loop over many EEG segments, e.g., 2-second windows.)\n",
        "if __name__ == \"__main__\":\n",
        "    # Generate a dummy EEG-like signal for demonstration\n",
        "    np.random.seed(0)\n",
        "    sample_eeg_segment = np.random.randn(512)  # e.g. 2 sec at 256 Hz, or any length\n",
        "\n",
        "    # Compute wavelet features\n",
        "    features = compute_dwt_features(\n",
        "        signal=sample_eeg_segment,\n",
        "        wavelet='db4',    # Example wavelet type\n",
        "        level=4           # Decomposition level\n",
        "    )\n",
        "\n",
        "    # Print sub-band feature results\n",
        "    print(\"Wavelet decomposition features:\")\n",
        "    for k, v in features.items():\n",
        "        if k != \"feature_vector\":\n",
        "            print(f\"{k}: Energy={v['energy']:.2f}, Var={v['variance']:.2f}, Entropy={v['entropy']:.2f}\")\n",
        "\n",
        "    # Print the combined vector\n",
        "    print(\"\\nCombined Feature Vector:\", features[\"feature_vector\"])\n"
      ],
      "metadata": {
        "id": "AkD9_yk5fEo4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Constructing a feature vector per window"
      ],
      "metadata": {
        "id": "FWcRmdnHOdrv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features_for_channel(signal, sf):\n",
        "    # Time-domain features\n",
        "    td_feats = compute_time_domain_features(signal)\n",
        "\n",
        "    # Frequency-domain features\n",
        "    freq_feats = {}\n",
        "    for band_name, freq_range in bands.items():\n",
        "        bp = bandpower(signal, sf, freq_range, window_sec=4, relative=True)\n",
        "        freq_feats[f'{band_name}_power'] = bp\n",
        "\n",
        "    # Entropy features\n",
        "    samp_en = sample_entropy(signal, order=2, r=0.2*np.std(signal))\n",
        "    p_en = perm_entropy(signal, order=3, normalize=True)\n",
        "    ent_feats = {\n",
        "        'sample_entropy': samp_en,\n",
        "        'perm_entropy': p_en\n",
        "    }\n",
        "\n",
        "    # Combine all dictionaries\n",
        "    combined = {**td_feats, **freq_feats, **ent_feats}\n",
        "    return combined\n",
        "\n",
        "# Example: looping over channels and windows\n",
        "all_features = []\n",
        "window_size = int(4 * sfreq)  # 4-second windows, for example\n",
        "overlap = 0.5  # 50% overlap\n",
        "\n",
        "step = int(window_size * (1 - overlap))\n",
        "n_samples = data.shape[1]\n",
        "\n",
        "for ch_idx in range(data.shape[0]):\n",
        "    ch_signal = data[ch_idx, :]\n",
        "    start = 0\n",
        "    while start + window_size < n_samples:\n",
        "        windowed_signal = ch_signal[start : start + window_size]\n",
        "        feats = extract_features_for_channel(windowed_signal, sfreq)\n",
        "        feats['channel'] = ch_names[ch_idx]\n",
        "        feats['start_sample'] = start\n",
        "        feats['end_sample'] = start + window_size\n",
        "        all_features.append(feats)\n",
        "        start += step\n",
        "\n",
        "df_features = pd.DataFrame(all_features)\n",
        "print(df_features.head())\n"
      ],
      "metadata": {
        "id": "9wL1CjxKOdYU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}