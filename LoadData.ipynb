{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import mne\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 54 entries, 0 to 53\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Unnamed: 0  54 non-null     int64 \n",
      " 1   subject_id  54 non-null     object\n",
      " 2   age         54 non-null     int64 \n",
      " 3   gender      54 non-null     object\n",
      " 4   edf_path    54 non-null     object\n",
      " 5   epilepsy    54 non-null     int64 \n",
      "dtypes: int64(3), object(3)\n",
      "memory usage: 2.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df_info = pd.read_csv('processed_eeg_data.csv')\n",
    "df_info.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>age</th>\n",
       "      <th>epilepsy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>54.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>54.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>26.500000</td>\n",
       "      <td>52.777778</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>15.732133</td>\n",
       "      <td>17.115222</td>\n",
       "      <td>0.501570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>13.250000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>26.500000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>39.750000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>53.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0        age   epilepsy\n",
       "count   54.000000  54.000000  54.000000\n",
       "mean    26.500000  52.777778   0.555556\n",
       "std     15.732133  17.115222   0.501570\n",
       "min      0.000000  24.000000   0.000000\n",
       "25%     13.250000  50.000000   0.000000\n",
       "50%     26.500000  53.000000   1.000000\n",
       "75%     39.750000  59.000000   1.000000\n",
       "max     53.000000  77.000000   1.000000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_info.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>edf_path</th>\n",
       "      <th>epilepsy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>aaaaamhx</td>\n",
       "      <td>57</td>\n",
       "      <td>F</td>\n",
       "      <td>EEG_Epilepsy/01_no_epilepsy/aaaaamhx/s001_2011...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>aaaaamhx</td>\n",
       "      <td>57</td>\n",
       "      <td>F</td>\n",
       "      <td>EEG_Epilepsy/01_no_epilepsy/aaaaamhx/s001_2011...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>aaaaamhx</td>\n",
       "      <td>57</td>\n",
       "      <td>F</td>\n",
       "      <td>EEG_Epilepsy/01_no_epilepsy/aaaaamhx/s001_2011...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>aaaaamhx</td>\n",
       "      <td>57</td>\n",
       "      <td>F</td>\n",
       "      <td>EEG_Epilepsy/01_no_epilepsy/aaaaamhx/s001_2011...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>aaaaamhx</td>\n",
       "      <td>57</td>\n",
       "      <td>F</td>\n",
       "      <td>EEG_Epilepsy/01_no_epilepsy/aaaaamhx/s001_2011...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 subject_id  age gender  \\\n",
       "0           0   aaaaamhx   57      F   \n",
       "1           1   aaaaamhx   57      F   \n",
       "2           2   aaaaamhx   57      F   \n",
       "3           3   aaaaamhx   57      F   \n",
       "4           4   aaaaamhx   57      F   \n",
       "\n",
       "                                            edf_path  epilepsy  \n",
       "0  EEG_Epilepsy/01_no_epilepsy/aaaaamhx/s001_2011...         0  \n",
       "1  EEG_Epilepsy/01_no_epilepsy/aaaaamhx/s001_2011...         0  \n",
       "2  EEG_Epilepsy/01_no_epilepsy/aaaaamhx/s001_2011...         0  \n",
       "3  EEG_Epilepsy/01_no_epilepsy/aaaaamhx/s001_2011...         0  \n",
       "4  EEG_Epilepsy/01_no_epilepsy/aaaaamhx/s001_2011...         0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_info.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_dataframe(df):\n",
    "    # Make a copy to avoid modifying the original dataframe\n",
    "\n",
    "    df_standardized = df.drop(['time','epoch', 'condition'], axis=1).copy()\n",
    "    \n",
    "    # Only standardize numeric columns\n",
    "    numeric_columns = df_standardized.select_dtypes(include=np.number).columns\n",
    "    \n",
    "    for column in numeric_columns:\n",
    "        mean = df[column].mean()\n",
    "        std = df[column].std()\n",
    "        \n",
    "        df_standardized[column] = (df[column] - mean) / std\n",
    "    \n",
    "    result = pd.concat([df[['time','epoch']], df_standardized], axis=1)\n",
    "\n",
    "    return result\n",
    "\n",
    "def preprocess_eeg_file(edf_path, fmin=0.7, fmax=45.0, segment_lenght=5, overlap=0):\n",
    "\n",
    "    # 1. Charger le fichier EDF avec MNE\n",
    "    raw = mne.io.read_raw_edf(edf_path, preload=True, verbose='ERROR')\n",
    "\n",
    "    # 2. Filtrage passe-bande (1-45 Hz)\n",
    "    raw.filter(fmin, fmax, fir_design='firwin', verbose=False)\n",
    "\n",
    "    # 3. Suppression des canaux non EEG\n",
    "    eeg_channels = mne.pick_types(raw.info, eeg=True, exclude=[])\n",
    "    raw.pick(eeg_channels)\n",
    "    col_to_drop = []\n",
    "    eeg_cols = raw.ch_names\n",
    "    for ch in (['RESP ABDOMEN-REF', 'IBI', 'BURSTS', 'SUPPR','EEG LOC-REF', 'EEG ROC-REF', 'EEG EKG1-REF']):\n",
    "        if ch in eeg_cols:\n",
    "            col_to_drop.append(ch)\n",
    "    raw.drop_channels(col_to_drop)\n",
    "\n",
    "    # 4. Segmentation\n",
    "    epochs = mne.make_fixed_length_epochs(raw, duration=segment_lenght, preload=False, overlap=overlap)\n",
    "\n",
    "    # 5. Transformation en DataFrame\n",
    "    \n",
    "    df = epochs.to_data_frame()\n",
    "\n",
    "    # 6. Normalisation canal par canal (centrage-r√©duction)\n",
    "\n",
    "    df_std = standardize_dataframe(df)\n",
    "    \n",
    "    return df_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Datas(df_info, n_subject = 10, epoch_per_acq = 1, balanced = True, random_state = 42):\n",
    "    \"\"\"\n",
    "\n",
    "    Description :\n",
    "    Cette fonction permet de charger et de pr√©traiter des donn√©es EEG √† partir d'un DataFrame contenant des informations \n",
    "    sur les patients et leurs fichiers EEG. Elle retourne les signaux EEG segment√©s (X) et leurs √©tiquettes associ√©es (y), \n",
    "    en fonction des param√®tres sp√©cifi√©s.\n",
    "\n",
    "    Param√®tres :\n",
    "    - df_info (DataFrame) : \n",
    "        Le DataFrame contenant les informations sur les patients, incluant les colonnes 'subject_id', 'edf_path' (chemin des fichiers EEG), \n",
    "        et 'epilepsy' (√©tiquette binaire indiquant la pr√©sence ou non d'√©pilepsie).\n",
    "    - n_subject (int, par d√©faut = 10) : \n",
    "        Le nombre total de patients √† inclure dans le dataset.\n",
    "    - epoch_per_acq (int, par d√©faut = 1) : \n",
    "        Le nombre de segments (ou \"epochs\") √† extraire pour chaque acquisition EEG.\n",
    "    - balanced (bool, par d√©faut = True) : \n",
    "        Si True, la fonction √©quilibre le dataset en s√©lectionnant un nombre √©gal de patients √©pileptiques et non √©pileptiques.\n",
    "    - random_state (int, par d√©faut = 42) : \n",
    "        La graine al√©atoire utilis√©e pour garantir la reproductibilit√© lors de l'√©chantillonnage des patients.\n",
    "\n",
    "    Retour :\n",
    "    - X (list) : \n",
    "        Une liste contenant les segments EEG extraits pour chaque patient.\n",
    "    - y (list) : \n",
    "        Une liste contenant les √©tiquettes correspondantes (1 pour √©pilepsie, 0 pour non √©pilepsie).\n",
    "    \"\"\"\n",
    "\n",
    "    X, y = [], []\n",
    "    # Clean df_info :\n",
    "    try:\n",
    "        df_info.drop(['Unnamed: 0', 'eeg_segments'], axis=1, inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "    paths = []\n",
    "    if balanced is True:\n",
    "        df = df_info.groupby('epilepsy', group_keys=False).apply(\n",
    "            lambda x: x.sample(n=int(n_subject/2), random_state=random_state)\n",
    "        )  # sample balanced classes\n",
    "    else:\n",
    "        df = df_info\n",
    "    for name in df['subject_id'].unique():\n",
    "        paths.append(df[df['subject_id']==name].iloc[:n_subject]['edf_path'])\n",
    "        \n",
    "    paths = pd.concat(paths)\n",
    "\n",
    "    for i in range(0,n_subject):\n",
    "        datas = preprocess_eeg_file(paths.iloc[i]) # Read preprocess the datas for each\n",
    "        for j in range(epoch_per_acq):   # We only add the first n intervals defined from param epoch_per_acq\n",
    "            X.append(datas[datas['epoch'] == j])\n",
    "            y.append(df_info[df_info['edf_path']==paths.iloc[i]].iloc[0]['epilepsy'])\n",
    "            print(i,j)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_9/27krwgwj75j8vh3qkqkhcjlh0000gn/T/ipykernel_55975/2713139585.py:39: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df_info.groupby('epilepsy', group_keys=False).apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "15 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1250 original time points ...\n",
      "0 bad epochs dropped\n",
      "0 0\n",
      "0 1\n",
      "0 2\n",
      "0 3\n",
      "0 4\n",
      "Not setting metadata\n",
      "15 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 15 events and 1250 original time points ...\n",
      "0 bad epochs dropped\n",
      "1 0\n",
      "1 1\n",
      "1 2\n",
      "1 3\n",
      "1 4\n",
      "Not setting metadata\n",
      "60 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 60 events and 1280 original time points ...\n",
      "0 bad epochs dropped\n",
      "2 0\n",
      "2 1\n",
      "2 2\n",
      "2 3\n",
      "2 4\n",
      "Not setting metadata\n",
      "10 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 10 events and 1250 original time points ...\n",
      "0 bad epochs dropped\n",
      "3 0\n",
      "3 1\n",
      "3 2\n",
      "3 3\n",
      "3 4\n",
      "Not setting metadata\n",
      "289 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 289 events and 1250 original time points ...\n",
      "0 bad epochs dropped\n",
      "4 0\n",
      "4 1\n",
      "4 2\n",
      "4 3\n",
      "4 4\n",
      "Not setting metadata\n",
      "6396 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 6396 events and 1280 original time points ...\n",
      "0 bad epochs dropped\n",
      "5 0\n",
      "5 1\n",
      "5 2\n",
      "5 3\n",
      "5 4\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 288 events and 1250 original time points ...\n",
      "0 bad epochs dropped\n",
      "6 0\n",
      "6 1\n",
      "6 2\n",
      "6 3\n",
      "6 4\n",
      "Not setting metadata\n",
      "288 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 288 events and 1250 original time points ...\n",
      "0 bad epochs dropped\n",
      "7 0\n",
      "7 1\n",
      "7 2\n",
      "7 3\n",
      "7 4\n",
      "Not setting metadata\n",
      "60 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 60 events and 1280 original time points ...\n",
      "0 bad epochs dropped\n",
      "8 0\n",
      "8 1\n",
      "8 2\n",
      "8 3\n",
      "8 4\n",
      "Not setting metadata\n",
      "120 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 120 events and 1280 original time points ...\n",
      "0 bad epochs dropped\n",
      "9 0\n",
      "9 1\n",
      "9 2\n",
      "9 3\n",
      "9 4\n",
      "X: 50 y: 50\n"
     ]
    }
   ],
   "source": [
    "X,y = get_Datas(df_info,10,5)\n",
    "\n",
    "print('X:',len(X), 'y:',len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 25)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y), sum(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Robin test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential\n",
    "\n",
    "# import tensorflow as tf\n",
    "# tf.keras.models.Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "# from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Dropout, Flatten, Dense, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Split train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2. Mod√®le CNN 1D\n",
    "model = Sequential([\n",
    "    Conv1D(32, kernel_size=5, activation='relu', input_shape=X.shape[1:]),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Conv1D(64, kernel_size=5, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.4),\n",
    "    Dense(1, activation='sigmoid')  # Pour classification binaire\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3. Compilation\n",
    "model.compile(optimizer=Adam(learning_rate=1e-3),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=15,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='Train')\n",
    "plt.plot(history.history['val_accuracy'], label='Val')\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Pr√©dictions \n",
    "y_pred_probs = model.predict(X_test)\n",
    "\n",
    "# Conversion en classes binaires (0 ou 1)\n",
    "y_pred = (y_pred_probs > 0.5).astype(int).flatten()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
